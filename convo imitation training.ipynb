{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"convo imitation training.ipynb","provenance":[],"authorship_tag":"ABX9TyOdcLQ0OUA/tibFHxBhI7QI"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"35a6c38b29a548a1b16a3e05de9a1983":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_04db0344c9cc4f1e82bc1cf805fe815d","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_ed595853093b4f828f701b4a4eb16962","IPY_MODEL_52e2472c66c4444eb4421eba0137638e"]}},"04db0344c9cc4f1e82bc1cf805fe815d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"ed595853093b4f828f701b4a4eb16962":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_6897d153d0a140758f2205c5bb55f55f","_dom_classes":[],"description":"100%","_model_name":"FloatProgressModel","bar_style":"success","max":51,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":51,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_d93433f70fb14304b294aa7326219d97"}},"52e2472c66c4444eb4421eba0137638e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_e0affd25d61241a78a52dcf92e60bbdd","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 51/51 [00:16&lt;00:00,  3.18it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_21371b22c6cc4afba7e78e72b1ecdd80"}},"6897d153d0a140758f2205c5bb55f55f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"d93433f70fb14304b294aa7326219d97":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"e0affd25d61241a78a52dcf92e60bbdd":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"21371b22c6cc4afba7e78e72b1ecdd80":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":52},"id":"iqAT4uzDF7qP","executionInfo":{"status":"ok","timestamp":1626284441288,"user_tz":-120,"elapsed":11,"user":{"displayName":"Karol Urbańczyk","photoUrl":"","userId":"16315446758580482711"}},"outputId":"5dfd55b1-94ce-49ad-fba8-3fa9675562d5"},"source":["'''\n","This notebook is intended to be used in google colab\n","\n","Majority of the code has been either inspired by or copied from Kaggle user:\n","https://www.kaggle.com/nejumi/let-s-create-your-agent-by-supervised-learning/notebook\n","\n","Some parts related to:\n","- tuning the model\n","- data transformation from JSON\n","were adjusted by us (Karol & Ammar)\n","'''"],"execution_count":1,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'\\nThis notebook is intended to be used in google colab\\n\\nMajority of the code has been either inspired by or copied from Kaggle user:\\nhttps://www.kaggle.com/nejumi/let-s-create-your-agent-by-supervised-learning/notebook\\n\\nSome parts related to:\\n- tuning the model\\n- data transformation from JSON\\nwere adjusted by us (Karol & Ammar)\\n'"]},"metadata":{"tags":[]},"execution_count":1}]},{"cell_type":"code","metadata":{"id":"CbCC1KSBLpJv","executionInfo":{"status":"ok","timestamp":1626284464960,"user_tz":-120,"elapsed":2102,"user":{"displayName":"Karol Urbańczyk","photoUrl":"","userId":"16315446758580482711"}}},"source":["# import libraries\n","import pickle\n","\n","import json\n","import gc\n","import bz2\n","import base64\n","from glob import glob\n","\n","import numpy as np\n","\n","import pandas as pd\n","from pandas import DataFrame\n","\n","from tqdm.notebook import tqdm\n","\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import log_loss, accuracy_score, recall_score\n","\n","import tensorflow as tf\n","from tensorflow.keras.preprocessing import image\n","from tensorflow.keras.models import Model, Sequential, load_model\n","from tensorflow.keras.layers import (GlobalAveragePooling2D, Dense, Conv2D, Activation, Lambda, Add, \n","                                     BatchNormalization, Input, Lambda)\n","from tensorflow.keras.utils import to_categorical, Sequence\n","from tensorflow.keras import backend as K\n","from tensorflow.keras.regularizers import l1_l2 ,l1, l2\n","from tensorflow.keras import mixed_precision"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sR2A_3NqKMdR","executionInfo":{"status":"ok","timestamp":1626284474312,"user_tz":-120,"elapsed":3290,"user":{"displayName":"Karol Urbańczyk","photoUrl":"","userId":"16315446758580482711"}},"outputId":"0023bbac-79be-485a-938b-3c701f8857dd"},"source":["!pip install tensorflow_addons"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Collecting tensorflow_addons\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/66/4b/e893d194e626c24b3df2253066aa418f46a432fdb68250cde14bf9bb0700/tensorflow_addons-0.13.0-cp37-cp37m-manylinux2010_x86_64.whl (679kB)\n","\r\u001b[K     |▌                               | 10kB 13.5MB/s eta 0:00:01\r\u001b[K     |█                               | 20kB 18.9MB/s eta 0:00:01\r\u001b[K     |█▌                              | 30kB 21.9MB/s eta 0:00:01\r\u001b[K     |██                              | 40kB 23.6MB/s eta 0:00:01\r\u001b[K     |██▍                             | 51kB 8.4MB/s eta 0:00:01\r\u001b[K     |███                             | 61kB 9.7MB/s eta 0:00:01\r\u001b[K     |███▍                            | 71kB 8.4MB/s eta 0:00:01\r\u001b[K     |███▉                            | 81kB 9.3MB/s eta 0:00:01\r\u001b[K     |████▍                           | 92kB 10.2MB/s eta 0:00:01\r\u001b[K     |████▉                           | 102kB 8.3MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 112kB 8.3MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 122kB 8.3MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 133kB 8.3MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 143kB 8.3MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 153kB 8.3MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 163kB 8.3MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 174kB 8.3MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 184kB 8.3MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 194kB 8.3MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 204kB 8.3MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 215kB 8.3MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 225kB 8.3MB/s eta 0:00:01\r\u001b[K     |███████████                     | 235kB 8.3MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 245kB 8.3MB/s eta 0:00:01\r\u001b[K     |████████████                    | 256kB 8.3MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 266kB 8.3MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 276kB 8.3MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 286kB 8.3MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 296kB 8.3MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 307kB 8.3MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 317kB 8.3MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 327kB 8.3MB/s eta 0:00:01\r\u001b[K     |████████████████                | 337kB 8.3MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 348kB 8.3MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 358kB 8.3MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 368kB 8.3MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 378kB 8.3MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 389kB 8.3MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 399kB 8.3MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 409kB 8.3MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 419kB 8.3MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 430kB 8.3MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 440kB 8.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 450kB 8.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 460kB 8.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 471kB 8.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 481kB 8.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 491kB 8.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 501kB 8.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 512kB 8.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 522kB 8.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 532kB 8.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 542kB 8.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 552kB 8.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 563kB 8.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 573kB 8.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 583kB 8.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 593kB 8.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 604kB 8.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 614kB 8.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 624kB 8.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 634kB 8.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 645kB 8.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 655kB 8.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 665kB 8.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 675kB 8.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 686kB 8.3MB/s \n","\u001b[?25hRequirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow_addons) (2.7.1)\n","Installing collected packages: tensorflow-addons\n","Successfully installed tensorflow-addons-0.13.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"YpnLCycxLuBs","executionInfo":{"status":"ok","timestamp":1626284478736,"user_tz":-120,"elapsed":254,"user":{"displayName":"Karol Urbańczyk","photoUrl":"","userId":"16315446758580482711"}}},"source":["import tensorflow as tf\n","from tensorflow_addons.utils.types import FloatTensorLike\n","\n","from typing import Union, Callable, Dict\n","from typeguard import typechecked\n","import numpy as np\n","\n","\n","@tf.keras.utils.register_keras_serializable(package=\"Addons\")\n","class RadaBelief(tf.keras.optimizers.Optimizer):\n","\n","    @typechecked\n","    def __init__(\n","            self,\n","            learning_rate: Union[FloatTensorLike, Callable, Dict] = 1e-4,\n","            beta_1: FloatTensorLike = 0.9,\n","            beta_2: FloatTensorLike = 0.999,\n","            epsilon: FloatTensorLike = 1e-12,\n","            warmup_steps: int = 10000,\n","            name: str = \"Radabelief\",\n","            **kwargs\n","    ):\n","        super().__init__(name, **kwargs)\n","\n","        self._set_hyper(\"learning_rate\", kwargs.get(\"lr\", learning_rate))\n","        self._set_hyper(\"beta_1\", beta_1)\n","        self._set_hyper(\"beta_2\", beta_2)\n","        self._set_hyper(\"warmup_steps\", warmup_steps)\n","        self.epsilon = epsilon or tf.keras.backend.epsilon()\n","\n","    def _create_slots(self, var_list):\n","        for var in var_list:\n","            self.add_slot(var, \"m\")\n","        for var in var_list:\n","            self.add_slot(var, \"v\")\n","\n","    def set_weights(self, weights):\n","        params = self.weights\n","        num_vars = int((len(params) - 1) / 2)\n","        if len(weights) == 3 * num_vars + 1:\n","            weights = weights[: len(params)]\n","        super().set_weights(weights)\n","\n","    def _resource_apply_dense(self, grad, var):\n","        var_dtype = var.dtype.base_dtype\n","\n","        # *current* learn rate of optimizer (changed by ReduceLROnPlateau for example)\n","        lr_t = self.lr\n","\n","        # get previous moments\n","        m = self.get_slot(var, \"m\")\n","        v = self.get_slot(var, \"v\")\n","\n","        # static hyperparameters of optimizer\n","        lr_0 = self._get_hyper(\"learning_rate\", var_dtype)\n","        warmup_steps = self._get_hyper(\"warmup_steps\", var_dtype)\n","        beta_1 = self._get_hyper(\"beta_1\", var_dtype)\n","        beta_2 = self._get_hyper(\"beta_2\", var_dtype)\n","\n","        # smaller epsilon == more bias == more like SGD\n","        # larger epsilon == more adaptive, potential for large LR difference between variables\n","        epsilon_t = tf.convert_to_tensor(self.epsilon, var_dtype)\n","\n","        # current step of optimizer\n","        local_step = tf.cast(self.iterations + 1, var_dtype)\n","\n","        # use linearly scaled lr from 0 to initial LR while steps under 'warmup_steps'\n","        lr = tf.where(\n","            local_step <= warmup_steps,\n","            (local_step / warmup_steps) * lr_0,\n","            lr_t,\n","        )\n","\n","        # calculate first moment of gradient (momemtum)\n","        m_t = m.assign(\n","            beta_1 * m + (1.0 - beta_1) * grad,\n","            use_locking=self._use_locking\n","        )\n","\n","        # calculate second moment of gradient (RMSprop)\n","        # use 'tf.square(grad - m_t)' for Adabelief instead of 'tf.square(grad)'\n","        v_t = v.assign(\n","            beta_2 * v + (1.0 - beta_2) * tf.square(grad - m_t),\n","            use_locking=self._use_locking,\n","        )\n","\n","        # correct bias (mostly affects initial steps)\n","        m_corr_t = m_t / (1.0 - tf.pow(beta_1, local_step))\n","        v_corr_t = v_t / (1.0 - tf.pow(beta_2, local_step))\n","\n","        # calculate step\n","        var_t = m_corr_t / (tf.sqrt(v_corr_t) + epsilon_t)\n","\n","        # apply learn rate\n","        var_update = var.assign_sub(lr * var_t,\n","                                    use_locking=self._use_locking)\n","\n","        updates = [var_update, m_t, v_t]\n","        return tf.group(*updates)\n","\n","    def get_config(self):\n","        config = super().get_config()\n","        config.update(\n","            {\n","                \"learning_rate\": self._serialize_hyperparameter(\"learning_rate\"),\n","                \"beta_1\": self._serialize_hyperparameter(\"beta_1\"),\n","                \"beta_2\": self._serialize_hyperparameter(\"beta_2\"),\n","                \"epsilon\": self.epsilon,\n","                \"warmup_steps\": self._serialize_hyperparameter(\"warmup_steps\"),\n","            }\n","        )\n","        return config"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"2y_bntLcFGba","executionInfo":{"status":"ok","timestamp":1626284483747,"user_tz":-120,"elapsed":243,"user":{"displayName":"Karol Urbańczyk","photoUrl":"","userId":"16315446758580482711"}}},"source":["import math\n","from tensorflow.keras.callbacks import Callback\n","from tensorflow.keras import backend as K\n","\n","class CosineAnnealingScheduler(Callback):\n","    \"\"\"Cosine annealing scheduler.\n","    \"\"\"\n","\n","    def __init__(self, T_max, eta_max, eta_min=0, verbose=0):\n","        super(CosineAnnealingScheduler, self).__init__()\n","        self.T_max = T_max\n","        self.eta_max = eta_max\n","        self.eta_min = eta_min\n","        self.verbose = verbose\n","\n","    def on_epoch_begin(self, epoch, logs=None):\n","        if not hasattr(self.model.optimizer, 'lr'):\n","            raise ValueError('Optimizer must have a \"lr\" attribute.')\n","        lr = self.eta_min + (self.eta_max - self.eta_min) * (1 + math.cos(math.pi * epoch / self.T_max)) / 2\n","        K.set_value(self.model.optimizer.lr, lr)\n","        if self.verbose > 0:\n","            print('\\nEpoch %05d: CosineAnnealingScheduler setting learning '\n","                  'rate to %s.' % (epoch + 1, lr))\n","\n","    def on_epoch_end(self, epoch, logs=None):\n","        logs = logs or {}\n","        logs['lr'] = K.get_value(self.model.optimizer.lr)"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"VeSuTYVPFJFH","executionInfo":{"status":"ok","timestamp":1626284487093,"user_tz":-120,"elapsed":220,"user":{"displayName":"Karol Urbańczyk","photoUrl":"","userId":"16315446758580482711"}}},"source":["# based on https://github.com/yu4u/mixup-generator\n","class GeeseDataGenerator(Sequence):\n","        'Generates data for Keras'\n","        def __init__(self, X_train, y_train, batch_size=128, shuffle=True, sample_weight=None):\n","            'Initialization'\n","            self.batch_size = batch_size\n","            self.X_train = X_train\n","            self.y_train = y_train\n","            self.shuffle = shuffle\n","            self.on_epoch_end()\n","            self.sample_weight = sample_weight\n","    \n","        def __len__(self):\n","            'Denotes the number of batches per epoch'\n","            return int(np.ceil(len(self.X_train) / self.batch_size))\n","    \n","        def __getitem__(self, index):\n","            'Generate one batch of data'\n","            # Generate indexes of the batch\n","            indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n","            # Generate data\n","            if self.sample_weight is not None:\n","                X, y, w = self.__data_generation(indexes)\n","                return X, y, w\n","            else:\n","                X, y = self.__data_generation(indexes)\n","                return X, y\n","    \n","        def on_epoch_end(self):\n","            'Updates indexes after each epoch'\n","            self.indexes = np.arange(len(self.X_train))\n","            if self.shuffle == True:\n","                np.random.shuffle(self.indexes)\n","        \n","        def __data_generation(self, batch_ids):\n","            #_, h, w, c = self.X_train.shape\n","        \n","            X = self.X_train[batch_ids]\n","            y = self.y_train[batch_ids]\n","            if self.sample_weight is not None:\n","                w = self.sample_weight[batch_ids]\n","            else:\n","                pass\n","            \n","            series_len = len(X)\n","            \n","            # vertical flip\n","            if np.random.uniform(0,1)>0.5:\n","                X = np.flip(X, axis=2)\n","                y = y[:,[0,1,3,2]]\n","                \n","            # horizontal flip\n","            if np.random.uniform(0,1)>0.5:\n","                X = np.flip(X, axis=1)\n","                y = y[:,[1,0,2,3]] \n","            \n","            if self.sample_weight is not None:\n","                return X, y, w\n","            else:\n","                return X, y"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"_wnJUzYaFKvq","executionInfo":{"status":"ok","timestamp":1626284548216,"user_tz":-120,"elapsed":244,"user":{"displayName":"Karol Urbańczyk","photoUrl":"","userId":"16315446758580482711"}}},"source":["#JSON transformation depending if it is supposed to learn from winner bot or human\n","\n","def create_dataset_from_json(filepath, json_object=None, standing=0, mode='bot'):\n","    if json_object is None:\n","        json_open = open(path, 'r')\n","        json_load = json.load(json_open)\n","    else:\n","        json_load = json_object\n","        \n","    try:\n","        \n","        rewards = [g['reward'] for g in json_load['steps'][-1]]\n","\n","        if mode=='bot':\n","            winner_index = np.argmax(np.argsort(rewards) == 3-standing)\n","        elif mode=='human':\n","            winner_index = 0\n","        else:\n","            print('who i should learn from?')\n","            return 0, 0\n","\n","        obses = []\n","        X = []\n","        y = []\n","        actions = {'NORTH':0, 'SOUTH':1, 'WEST':2, 'EAST':3}\n","\n","        for i in range(len(json_load['steps'])-1):\n","            if json_load['steps'][i][winner_index]['status'] == 'ACTIVE':\n","                y_= json_load['steps'][i+1][winner_index]['action']\n","                if y_ is not None:\n","                    step = json_load['steps'][i]\n","                    step[winner_index]['observation']['geese'] = step[0]['observation']['geese']\n","                    step[winner_index]['observation']['food'] = step[0]['observation']['food']\n","                    obses.append(step[winner_index]['observation'])\n","                    y.append(actions[y_])        \n","\n","        for j in range(len(obses)):\n","            X_ = make_input(obses[:j+1])\n","            X_ = centerize(X_)\n","            X.append(X_)\n","\n","        X = np.array(X, dtype=np.float32)#[starting_step:]\n","        y = np.array(y, dtype=np.uint8)#[starting_step:]\n","\n","        return X, y\n","    except:\n","        return 0, 0"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"MIrj9WW4FMTr","executionInfo":{"status":"ok","timestamp":1626284551875,"user_tz":-120,"elapsed":250,"user":{"displayName":"Karol Urbańczyk","photoUrl":"","userId":"16315446758580482711"}}},"source":["# based on https://www.kaggle.com/yuricat/smart-geese-trained-by-reinforcement-learning\n","def centerize(b):\n","    dy, dx = np.where(b[0])\n","    centerize_y = (np.arange(0,7)-3+dy[0])%7\n","    centerize_x = (np.arange(0,11)-5+dx[0])%11\n","    \n","    b = b[:, centerize_y,:]\n","    b = b[:, :,centerize_x]\n","    \n","    return b\n","\n","def make_input(obses):\n","    b = np.zeros((17, 7 * 11), dtype=np.float32)\n","    obs = obses[-1]\n","\n","    for p, pos_list in enumerate(obs['geese']):\n","        # head position\n","        for pos in pos_list[:1]:\n","            b[0 + (p - obs['index']) % 4, pos] = 1\n","        # tip position\n","        for pos in pos_list[-1:]:\n","            b[4 + (p - obs['index']) % 4, pos] = 1\n","        # whole position\n","        for pos in pos_list:\n","            b[8 + (p - obs['index']) % 4, pos] = 1\n","            \n","    # previous head position\n","    if len(obses) > 1:\n","        obs_prev = obses[-2]\n","        for p, pos_list in enumerate(obs_prev['geese']):\n","            for pos in pos_list[:1]:\n","                b[12 + (p - obs['index']) % 4, pos] = 1\n","\n","    # food\n","    for pos in obs['food']:\n","        b[16, pos] = 1\n","        \n","    b = b.reshape(-1, 7, 11)\n","    b = centerize(b) # Where to place the head is arbiterary dicision.\n","\n","    return b"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"4_l154yCFdBm","executionInfo":{"status":"ok","timestamp":1626284557395,"user_tz":-120,"elapsed":218,"user":{"displayName":"Karol Urbańczyk","photoUrl":"","userId":"16315446758580482711"}}},"source":["# based on https://www.kaggle.com/yuricat/smart-geese-trained-by-reinforcement-learning\n","def TorusConv2D(x, ch, kernel, padding=\"same\", strides=1, weight_decay=2e-3):\n","    x = Lambda(lambda x: K.tile(x, n=(1,3,3,1)), \n","               output_shape=lambda input_shape: (None, 3*input_shape[1], 3*input_shape[2], input_shape[3]))(x)\n","    \n","    x = Conv2D(ch, kernel, padding=padding, strides=strides,\n","                      kernel_regularizer=l2(weight_decay))(x)\n","    \n","    x = Lambda(lambda x: x[:,int(x.shape[1]/3):2*int(x.shape[1]/3), int(x.shape[2]/3):2*int(x.shape[2]/3),:], \n","               output_shape=lambda input_shape: (None, int(input_shape[1]/3), int(input_shape[2]/3), input_shape[3]))(x)\n","    return x\n","\n","def conv_bn_relu(x0, ch, kernel, padding=\"same\", strides=1, weight_decay=2e-3, add=False):\n","    x = TorusConv2D(x0, ch, kernel, padding=padding, strides=strides,\n","                      weight_decay=weight_decay)\n","    x = BatchNormalization()(x)\n","    x = Activation(\"relu\")(x)\n","    if add:\n","        x = Add()([x0, x])\n","    return x\n","\n","def GeeseNet(input_shape=(7, 11, 17), layers=12, filters=32, weight_decay=2e-3, compile=True):\n","    input = Input(input_shape)\n","    x = conv_bn_relu(input, filters, 3)\n","    \n","    for i in range(layers):\n","        x = conv_bn_relu(x, filters, 3, add=True)\n","    \n","    x = GlobalAveragePooling2D()(x)\n","    \n","    output = Dense(4, activation='softmax', kernel_regularizer=l1_l2(l1=0.0005, l2=0.0005))(x)   \n","    model = Model(input, output)\n","    if compile:\n","        model.compile(optimizer=RadaBelief(learning_rate=1e-3, epsilon=1e-5), loss='categorical_crossentropy', metrics=['accuracy'])\n","    else:\n","        pass\n","    \n","    return model"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lobbJegtFiRM","executionInfo":{"status":"ok","timestamp":1626284566304,"user_tz":-120,"elapsed":6083,"user":{"displayName":"Karol Urbańczyk","photoUrl":"","userId":"16315446758580482711"}},"outputId":"c2f4bf21-27e9-4a68-f19d-28e57cf99589"},"source":["# use mixed precision\n","policy = mixed_precision.experimental.Policy('mixed_float16')\n","mixed_precision.experimental.set_policy(policy)"],"execution_count":10,"outputs":[{"output_type":"stream","text":["INFO:tensorflow:Mixed precision compatibility check (mixed_float16): OK\n","Your GPU will likely run quickly with dtype policy mixed_float16 as it has compute capability of at least 7.0. Your GPU: Tesla T4, compute capability 7.5\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/mixed_precision/loss_scale.py:51: DynamicLossScale.__init__ (from tensorflow.python.training.experimental.loss_scale) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.keras.mixed_precision.LossScaleOptimizer instead. LossScaleOptimizer now has all the functionality of DynamicLossScale\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Nde4EGG-M6ZN","executionInfo":{"status":"ok","timestamp":1625681525797,"user_tz":-120,"elapsed":17881,"user":{"displayName":"Karol Urbańczyk","photoUrl":"","userId":"16315446758580482711"}},"outputId":"644b5ec4-6373-428e-c5d3-0dc468e14c73"},"source":["from google.colab import drive\n","drive.mount('/content/drive/')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive/\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":83,"referenced_widgets":["35a6c38b29a548a1b16a3e05de9a1983","04db0344c9cc4f1e82bc1cf805fe815d","ed595853093b4f828f701b4a4eb16962","52e2472c66c4444eb4421eba0137638e","6897d153d0a140758f2205c5bb55f55f","d93433f70fb14304b294aa7326219d97","e0affd25d61241a78a52dcf92e60bbdd","21371b22c6cc4afba7e78e72b1ecdd80"]},"id":"AJdEpqKlFkPf","executionInfo":{"status":"ok","timestamp":1625681787571,"user_tz":-120,"elapsed":17303,"user":{"displayName":"Karol Urbańczyk","photoUrl":"","userId":"16315446758580482711"}},"outputId":"1e118d9d-3bc4-48aa-90bc-66eca79ca2ea"},"source":["import os\n","\n","mode = 'human' #/should it learn from human or a bot?\n","\n","#adapt it to the paths where you store JSONs\n","if mode=='bot':\n","  paths = [f'/content/drive/MyDrive/Colab_Notebooks/LMU_HCA/results/{path}' for path in os.listdir(path='/content/drive/MyDrive/Colab_Notebooks/LMU_HCA/results/') if 'info' not in path]\n","elif mode=='human':\n","  folders = [f'/content/drive/MyDrive/Colab_Notebooks/LMU_HCA/human/{path}' for path in os.listdir(path='/content/drive/MyDrive/Colab_Notebooks/LMU_HCA/human/')]\n","  paths = []\n","  for f in folders:\n","    paths += [f'{f}/{path}' for path in os.listdir(path=f)]\n","\n","print(len(paths))\n","\n","X_train = []\n","y_train = []\n","\n","for path in tqdm(paths[:int(len(paths))]):\n","  X, y = create_dataset_from_json(path, mode=mode) # use only winners' moves\n","  if X is not 0:\n","    X_train.append(X)\n","    y_train.append(y)\n","    \n","X_train = np.concatenate(X_train)\n","y_train = np.concatenate(y_train)\n","\n","X_train, unique_index = np.unique(X_train, axis=0, return_index=True)\n","y_train = y_train[unique_index]\n","\n","X_train = np.transpose(X_train, [0, 2, 3, 1])\n","y_train = to_categorical(y_train)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["51\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"35a6c38b29a548a1b16a3e05de9a1983","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=51.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_52WbrKVFnF3","executionInfo":{"status":"ok","timestamp":1625681789051,"user_tz":-120,"elapsed":254,"user":{"displayName":"Karol Urbańczyk","photoUrl":"","userId":"16315446758580482711"}},"outputId":"6d60d5c4-104d-4528-e220-1624b07dc6e8"},"source":["X_train.shape, y_train.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["((4498, 7, 11, 17), (4498, 4))"]},"metadata":{"tags":[]},"execution_count":14}]},{"cell_type":"code","metadata":{"id":"QRXkleVbFo4Q","colab":{"base_uri":"https://localhost:8080/","height":374},"executionInfo":{"status":"error","timestamp":1625649294169,"user_tz":-120,"elapsed":4948,"user":{"displayName":"Karol Urbańczyk","photoUrl":"","userId":"16315446758580482711"}},"outputId":"c92e7c62-212c-44a3-b63e-1ea74fe77b48"},"source":["alpha=0.3\n","batch_size = 32\n","val_size = 0.2\n","\n","X_train_, X_val, y_train_, y_val = train_test_split(X_train, y_train, test_size=val_size, random_state=71)\n","\n","training_generator = GeeseDataGenerator(X_train_, (1-alpha)*y_train_+0.25*alpha, batch_size=batch_size)\n","cos = CosineAnnealingScheduler(10, 2e-3*batch_size/32, 0, verbose=1)\n","\n","#changed 12 to 2 layers, epochs 11 to 2\n","model = GeeseNet(input_shape=(7, 11, 17), layers=12, filters=32, weight_decay=1e-7, compile=True)\n","model.fit(training_generator, validation_data=(X_val, y_val), epochs=11, batch_size=batch_size, callbacks=[cos])\n","model.save('model.h5')"],"execution_count":null,"outputs":[{"output_type":"stream","text":[" 441/1951 [=====>........................] - ETA: 1:55 - loss: 1.0762 - accuracy: 0.7348"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-60-e3fa16c321a3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m#changed 12 to 2 layers, epochs 11 to 2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGeeseNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m11\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m17\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_decay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_generator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcos\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1181\u001b[0m                 _r=1):\n\u001b[1;32m   1182\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1183\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1184\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1185\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    887\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    915\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3022\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   3023\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 3024\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   3025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3026\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1959\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1960\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1961\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1962\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1963\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    594\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 596\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    597\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m           outputs = execute.execute_with_cancellation(\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"K1FD9ygyFq2L","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1625646828318,"user_tz":-120,"elapsed":516,"user":{"displayName":"Karol Urbańczyk","photoUrl":"","userId":"16315446758580482711"}},"outputId":"a2717bf6-c2bb-4ad7-cd48-e82636c6762f"},"source":["# Write weight to the head of the python script\n","weight_base64 = base64.b64encode(bz2.compress(pickle.dumps(model.get_weights())))\n","w = \"weight= %s\"%weight_base64\n","%store w >imitation.py"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Writing 'w' (str) to file 'imitation_human.py'.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"I8KFSoYjG2IC"},"source":["!mv imitation.py /content/drive/MyDrive/Colab_Notebooks/LMU_HCA/imitation_human.py"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wkYuiY1ZFtAj","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1625646856151,"user_tz":-120,"elapsed":513,"user":{"displayName":"Karol Urbańczyk","photoUrl":"","userId":"16315446758580482711"}},"outputId":"0aec642b-118f-43bf-e9ad-d171e9863e5d"},"source":["%%writefile -a imitation.py\n","import pickle\n","import bz2\n","import base64\n","import numpy as np\n","\n","import tensorflow as tf\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Conv2D, Activation, Lambda, Add, BatchNormalization, Input\n","from tensorflow.keras import backend as K\n","from tensorflow.keras.regularizers import l1_l2, l2\n","\n","\n","# Neural Network for Hungry Geese\n","def TorusConv2D(x, ch, kernel, padding=\"same\", strides=1, weight_decay=2e-3):\n","    x = Lambda(lambda x: K.tile(x, n=(1,3,3,1)), \n","               output_shape=lambda input_shape: (None, 3*input_shape[1], 3*input_shape[2], input_shape[3]))(x)\n","    \n","    x = Conv2D(ch, kernel, padding=padding, strides=strides,\n","                      kernel_regularizer=l2(weight_decay))(x)\n","    \n","    x = Lambda(lambda x: x[:,int(x.shape[1]/3):2*int(x.shape[1]/3), int(x.shape[2]/3):2*int(x.shape[2]/3),:], \n","               output_shape=lambda input_shape: (None, int(input_shape[1]/3), int(input_shape[2]/3), input_shape[3]))(x)\n","    return x\n","\n","def conv_bn_relu(x0, ch, kernel, padding=\"same\", strides=1, weight_decay=2e-3, add=False):\n","    x = TorusConv2D(x0, ch, kernel, padding=padding, strides=strides,\n","                      weight_decay=weight_decay)\n","    x = BatchNormalization()(x)\n","    x = Activation(\"relu\")(x)\n","    if add:\n","        x = Add()([x0, x])\n","    return x\n","\n","def GeeseNet(input_shape=(7, 11, 17), layers=12, filters=32, weight_decay=2e-3):\n","    input = Input(input_shape)\n","    x = conv_bn_relu(input, filters, 3)\n","    \n","    for i in range(layers):\n","        x = conv_bn_relu(x, filters, 3, add=True)\n","    \n","    x = GlobalAveragePooling2D()(x)\n","    \n","    output = Dense(4, activation='softmax', kernel_regularizer=l1_l2(l1=0.0005, l2=0.0005))(x)   \n","    model = Model(input, output)\n","    #model.compile(optimizer=RadaBelief(learning_rate=1e-3, epsilon=1e-5), loss='categorical_crossentropy', metrics=['accuracy'])    \n","    \n","    return model\n","\n","# Input for Neural Network\n","def centerize(b):\n","    dy, dx = np.where(b[0])\n","    centerize_y = (np.arange(0,7)-3+dy[0])%7\n","    centerize_x = (np.arange(0,11)-5+dx[0])%11\n","    \n","    b = b[:, centerize_y,:]\n","    b = b[:, :,centerize_x]\n","    \n","    return b\n","\n","def make_input(obses):\n","    b = np.zeros((17, 7 * 11), dtype=np.float32)\n","    obs = obses[-1]\n","\n","    for p, pos_list in enumerate(obs['geese']):\n","        # head position\n","        for pos in pos_list[:1]:\n","            b[0 + (p - obs['index']) % 4, pos] = 1\n","        # tip position\n","        for pos in pos_list[-1:]:\n","            b[4 + (p - obs['index']) % 4, pos] = 1\n","        # whole position\n","        for pos in pos_list:\n","            b[8 + (p - obs['index']) % 4, pos] = 1\n","            \n","    # previous head position\n","    if len(obses) > 1:\n","        obs_prev = obses[-2]\n","        for p, pos_list in enumerate(obs_prev['geese']):\n","            for pos in pos_list[:1]:\n","                b[12 + (p - obs['index']) % 4, pos] = 1\n","\n","    # food\n","    for pos in obs['food']:\n","        b[16, pos] = 1\n","        \n","    b = b.reshape(-1, 7, 11)\n","    b = centerize(b) # Where to place the head is arbiterary dicision.\n","\n","    return b\n","\n","\n","# Load Keras Model\n","model = GeeseNet(input_shape=(7, 11, 17), layers=12, filters=32, weight_decay=1e-7)\n","model.set_weights(pickle.loads(bz2.decompress(base64.b64decode(weight))))\n","\n","# Main Function of Agent\n","\n","obses = []\n","\n","def agent(obs_dict, config_dict):\n","    obses.append(obs_dict)\n","\n","    X_test = make_input(obses)\n","    X_test = np.transpose(X_test, (1,2,0))\n","    X_test = X_test.reshape(-1,7,11,17) # channel last.\n","    \n","    # avoid suicide\n","    obstacles = X_test[:,:,:,[8,9,10,11,12]].max(axis=3) - X_test[:,:,:,[4,5,6,7]].max(axis=3) # body + opposite_side - my tail\n","    obstacles = np.array([obstacles[0,2,5], obstacles[0,4,5], obstacles[0,3,4], obstacles[0,3,6]])\n","    \n","    y_pred = model.predict(X_test) - obstacles\n","\n","    actions = ['NORTH', 'SOUTH', 'WEST', 'EAST']\n","    return actions[np.argmax(y_pred)]"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Appending to imitation_human.py\n"],"name":"stdout"}]}]}